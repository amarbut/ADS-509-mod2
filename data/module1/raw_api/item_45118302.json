{"by": "andrewmonostate", "descendants": 0, "id": 45118302, "score": 5, "text": "TLDR: A small, vendor-agnostic inference loop that turns token logprobs&#x2F;perplexity&#x2F;entropy into an extra pass and reasoning for LLMs.<p>- Captures logprobs&#x2F;top-k during generation, computes perplexity and token-level entropy.<p>- Triggers at most one refine when simple thresholds fire; passes a compact \u201cuncertainty report\u201d (uncertain tokens + top-k alts + local context) back to the model.<p>- In our tests on technical Q&amp;A &#x2F; math &#x2F; code, a small model recovered much of \u201creasoning\u201d quality at ~\u2153 the cost while refining ~\u2153 of outputs.<p>I kept seeing \u201creasoning\u201d models behave like expensive black boxes. Meanwhile, standard inference already computes useful signals both before softmax normalization and after it(logprobs), which we usually throw away. This loop tries the simplest thing that you could think of: use those signals to decide when (and where) to think again.<p>GitHub (notebook + minimal code): <a href=\"https:&#x2F;&#x2F;github.com&#x2F;monostate&#x2F;weave-logprobs-reasoning-loop\" rel=\"nofollow\">https:&#x2F;&#x2F;github.com&#x2F;monostate&#x2F;weave-logprobs-reasoning-loop</a><p>Paper (short &amp; engineer made):\n<a href=\"https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2509.00079\" rel=\"nofollow\">https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2509.00079</a><p>Blog (more context): <a href=\"https:&#x2F;&#x2F;monostate.ai&#x2F;blog&#x2F;entropy-refinement-blog\" rel=\"nofollow\">https:&#x2F;&#x2F;monostate.ai&#x2F;blog&#x2F;entropy-refinement-blog</a><p>Requirements: Python, API that exposes logprobs (tested with OpenAI non reasoning 4.1). OPENAI_API_KEY and WEAVE for observability. Run the notebook; it prints metrics and shows which tokens triggered refinement.<p>- Python, simple loop (no retraining).<p>- Uses Responses API logprobs&#x2F;top-k; metrics: perplexity, max token entropy, low-confidence counts.<p>- Weave for lightweight logging&#x2F;observability (optional).<p>- Passing alternatives (not just \u201cthis looks uncertain\u201d) prevents over-correction.<p>- A simple OR rule (ppl &#x2F; max-entropy &#x2F; low-confidence count) catches complementary failure modes.<p>- Numbers drift across vendors; keeping the method vendor-agnostic is better than chasing fragile pairings.<p>- Needs APIs that expose logprobs&#x2F;top-k.<p>- Results are indicative\u2014not a leaderboard; focus is on within-model gains (single-pass vs +loop).<p>- Thresholds might need light tuning per domain.<p>- One pass only; not a chain-of-thought replacement.<p>- Run it on your models and ideas (e.g., 4o-mini, v3, Llama variants with logprobs) and share logs in a PR for our README in GitHub if you&#x27;d like, PRs welcome - I\u2019ll credit and link.<p>Overall let me know if you find making small models reason like this useful!", "time": 1756919950, "title": "Show HN: Entropy-Guided Loop \u2013 How to make small models reason", "type": "story", "url": "https://github.com/monostate/weave-logprobs-reasoning-loop"}